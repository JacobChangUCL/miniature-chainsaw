# Security and privay individual coursework
## the structure of the project
```plaintext
security-and-privacy/                
│
├── Online_Forum_Safe_Version/       # The code for Coursework 2
│   │
│   ├── instance/                   
│   │   └── userPasswd.db            # The database for storing usernames and hashed passwords
│   │
│   ├── static/                      # Static files for the website
│   │   └── css/                     
│   │       └── style1.css           # The CSS file for the website
│   │
│   ├── templates/                   
│   │   ├── login.html               # The login page of the website
│   │   └── upload.html              # The page for sharing comics
│   │
│   ├── utils/                       
│   │   ├── __init__.py
│   │   └── login_attempt_limitation.py  # The code for limiting the number of login attempts using a dictionary
│   │
│   └── app.py                       # The backend code for the website
│
├── Online_Forum_Unsafe_Version/     # The code for Coursework 1
│   │
│   ├── instance/                    
│   │   └── userPasswd.db            # Same as above, details are not repeated below.
│   │   
│   ├── static/                      
│   │   ├── css/                    
│   │   │   └── style1.css                   
│   │   │
│   ├── templates/                 
│   │   ├── login.html              
│   │   └── upload.html              
│   │
│   └── app.py                       
│
├── adversarial_attack/            # The data and code for adversarial attack
│   │  
│   ├── captcha/                   # Adversarial CAPTCHA generated by STGM(Stocastic Transformation Gradient Method)
│   │   ├── chair/                 # The CAPTCHA images which have "chair" as their original label 
│   │   ├── cup/                   ...
│   │   ├── elephant/              ...
│   │   └── laptop/                ...
│   │
│   ├── data/                      # raw images for generating adversarial examples
│   │   ├── caltech101             # Caltech 101 dataset
│   │   └── tiny-imagenet-200      # Tiny ImageNet-200 dataset(deprecated)
│   │
│   ├── environment.yaml      # Environment configuration file
│   ├── STGM.ipynb            # STGM adversarial example notebook
│   └── STGM_batch_version.py # STGM batch version script
│    
│   
├── attacker/                             # Attacker scripts and related files
│   ├── 200-most-common-passwords-en.pdf  # PDF of 200 most common passwords
│   ├── Common Password List.txt          # Common password list in text format,for dictonary attack
│   ├── dictionary_attack.py              
│   ├── http_flood.py                     
│   └── SQL injection list.txt            # SQL injection commands
│
├── README.md
│
└── requirements.txt
```
usage:<br>
for the online forum safe version & unsafe version:
```plaintext
    conda create -n security python=3.12
    conda activate security
    pip install -r requirements_online_forum.txt
    cd Online_Forum_Safe_Version       # or Online_Forum_Unsafe_Version
    python app.py
```
Then click the link to enter the URL http://127.0.0.1:5000.<br>

execute various attacks in the attacker folder:  
(please make sure the server is running)
```plaintext
    cd attacker
    python dictionary_attack.py
    python http_flood.py
```
for SQL injection attack, please enter the SQL injection commands in SQL injection list.txt to test the website.  

for adversarial attack:
```plaintext
    conda create -n adversarial python=3.12.3
    conda activate adversarial
    pip install -r requirements_adversarial.txt
    cd adversarial_attack
    python STGM_batch_version.py
```
The STGM_batch_version.py file will generate adversarial examples using STGM(stochastic targeted gradient method).
